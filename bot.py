# âœ… main.pyï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼Œä¿ç•™æ–°ç‰ˆè¨˜æ†¶ + åŸæœ¬é—œæ©Ÿæ­¸æª”èˆ‡æ‘˜è¦åŠŸèƒ½ï¼‰
import os
import time
import signal
from dotenv import load_dotenv
import discord
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.chat_history import InMemoryChatMessageHistory
from log_archiver import (
    log_message, archive_now, load_latest_archive,
    student_logs, save_summary, load_summary
)
import re
import json

load_dotenv()

DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

load_latest_archive()

intents = discord.Intents.default()
intents.messages = True
intents.message_content = True
client = discord.Client(intents=intents)

user_sessions = {}

DEFAULT_PROMPT = (
    "å¿…é ˆä½¿ç”¨ä¸­æ–‡"
    "ä½ æœ‰å°å­¸ç”Ÿéå¾€çš„æå•ç´€éŒ„ï¼Œå¯ä»¥åƒè€ƒé€™äº›ä¸Šä¸‹æ–‡ä¾†åˆ¤æ–·æœ¬æ¬¡å›è¦†ã€‚\n"
    "ä½ æ˜¯ä¸€ä½ç²¾ç°¡ä¸”å°ˆæ¥­çš„ Python åŠ©æ•™ï¼Œè«‹é‡å°å­¸ç”Ÿå•é¡Œçµ¦å‡ºç›´æ¥ã€æœ‰æ•ˆçš„æç¤ºï¼Œ"
    "é¿å…è´…è©ï¼Œé¼“å‹µå­¸ç”Ÿè‡ªè¡Œæ€è€ƒèˆ‡æŸ¥è©¢ï¼Œå¿…è¦æ™‚æä¾›å°ˆæ¥­è¡“èªèˆ‡å¯¦ä¾‹ã€‚\n\n"
    "è«‹å°‡å›è¦†æ§åˆ¶åœ¨ 5~8 è¡Œä»¥å…§ã€ç¸½é•·åº¦ä¸è¶…é 6 æ®µï¼Œé¿å…å†—é•·æè¿°ã€‚æ•´é«”å›è¦†è«‹å£“åœ¨ 450 tokens ä»¥å…§ã€‚\n"
    "å¦‚æœåŒ…å«ç¨‹å¼ç¢¼ï¼Œè«‹ä½¿ç”¨ ```python å€å¡Šå‘ˆç¾ï¼Œä¸”åªæä¾›ä¸€å€‹ç°¡æ½”ç¯„ä¾‹ï¼Œä¸¦ä»¥ ``` çµæŸã€‚\n"
    "ğŸ”¹ å¦‚æœå­¸ç”Ÿçš„è¼¸å…¥æ˜¯ä¸€å€‹å•é¡Œï¼Œè«‹ä¾ç…§ä»–ç¨‹åº¦çµ¦å‡ºåˆé©çš„è§£é‡‹ã€‚\n"
    "ğŸ”¹ è‹¥å­¸ç”Ÿä½¿ç”¨ `XXX -e` é€™ç¨®æ ¼å¼ï¼Œè«‹æä¾›ä¸€å€‹ç›¸é—œç¯„ä¾‹ä¸¦ç°¡è¦èªªæ˜å…¶ç”¨é€”ã€‚\n"
    "è«‹ç¢ºä¿èªæ°£æ¸…æ™°ã€å›æ‡‰æœ‰å±¤æ¬¡ã€‚"
)

LOW_ACHIEVER_PROMPT = (
    "å¿…é ˆä½¿ç”¨ä¸­æ–‡"
    "ä½ æœ‰å°å­¸ç”Ÿéå¾€çš„æå•ç´€éŒ„ï¼Œå¯ä»¥åƒè€ƒé€™äº›ä¸Šä¸‹æ–‡ä¾†åˆ¤æ–·æœ¬æ¬¡å›è¦†ã€‚\n"
    "ä½ æ˜¯ä¸€ä½éå¸¸æœ‰è€å¿ƒä¸”å–„æ–¼å¼•å°çš„ Python åŠ©æ•™ï¼Œé¢å°åŸºç¤å°šæœªæ‰å¯¦çš„å­¸ç”Ÿï¼Œ"
    "è«‹é¿å…ç›´æ¥çµ¦å‡ºç­”æ¡ˆï¼Œä¸¦ä»¥ç°¡å–®èˆ‰ä¾‹èˆ‡æå•çš„æ–¹å¼å¹«åŠ©å­¸ç”Ÿæ€è€ƒï¼Œ"
    "ä¾‹å¦‚ç”Ÿæ´»åŒ–æ¯”å–»ã€åå•ã€å¾ªåºæ¼¸é€²çš„è§£é‡‹æ–¹å¼ï¼Œå»ºç«‹ä¿¡å¿ƒèˆ‡ç†è§£åŠ›ã€‚\n\n"
    "è«‹å°‡å›è¦†æ§åˆ¶åœ¨ 5~8 è¡Œä»¥å…§ã€ç¸½é•·åº¦ä¸è¶…é 6 æ®µï¼Œé¿å…å†—é•·æè¿°ã€‚æ•´é«”å›è¦†è«‹å£“åœ¨ 450 tokens ä»¥å…§ã€‚\n"
    "å¦‚æœåŒ…å«ç¨‹å¼ç¢¼ï¼Œè«‹ä½¿ç”¨ ```python å€å¡Šå‘ˆç¾ï¼Œä¸”åªæä¾›ä¸€å€‹ç°¡æ½”ç¯„ä¾‹ï¼Œä¸¦ä»¥ ``` çµæŸã€‚\n"
    "ğŸ”¹ å¦‚æœå­¸ç”Ÿè¼¸å…¥çš„æ˜¯ä¸€æ®µ Python ç¨‹å¼ç¢¼ï¼Œè«‹ä¸è¦ç«‹åˆ»è§£é‡‹ï¼Œ"
    "è€Œæ˜¯è©¢å•å­¸ç”Ÿå¸Œæœ›å¾ä»¥ä¸‹å“ªå€‹æ–¹å‘ç²å¾—å¹«åŠ©ï¼Œä¸¦è«‹ä»–é¸æ“‡å°æ‡‰çš„æ•¸å­—ï¼š\n"
    "1ï¸âƒ£ é‚è¼¯è§£é‡‹\n2ï¸âƒ£ èªæ³•èªªæ˜\n3ï¸âƒ£ æ›å€‹å¯«æ³•\n4ï¸âƒ£ åŠ ä¸Šè¨»è§£\n5ï¸âƒ£ ç¨‹å¼ç¢¼æª¢æŸ¥\n"
    "è«‹ç­‰å¾…å­¸ç”Ÿå›è¦†æ•¸å­—å¾Œå†ä¾æŒ‡ä»¤é€²è¡Œã€‚\n\n"
    "ğŸ”¹ å¦‚æœå­¸ç”Ÿçš„è¼¸å…¥æ˜¯ä¸€å€‹å•é¡Œï¼Œè«‹ç”¨ç°¡å–®æ¯”å–»æˆ–åˆ†æ®µèªªæ˜å¹«åŠ©ä»–ç†è§£ã€‚\n"
    "ğŸ”¹ è‹¥å­¸ç”Ÿä½¿ç”¨ `XXX -e` é€™ç¨®æ ¼å¼ï¼Œè«‹æä¾›ä¸€å€‹ç›¸é—œç¯„ä¾‹ä¸¦ç”¨ç™½è©±è§£é‡‹å…¶ç”¨é€”ã€‚"
)

def get_system_prompt(student_level: str) -> str:
    return LOW_ACHIEVER_PROMPT if student_level == "02" else DEFAULT_PROMPT

def preprocess_message(message: str) -> str:
    message = message.replace('\u3000', ' ')
    if message.endswith(" -e"):
        topic = message[:-3].strip()
        return f"è«‹èˆ‰ä¸€å€‹ Python ä¸­ã€Œ{topic}ã€ çš„ä½¿ç”¨ç¯„ä¾‹ï¼Œä¸¦èªªæ˜å®ƒçš„ç”¨é€”ã€‚"
    return message

def semantic_split(text, limit=1800):
    if len(text) <= limit:
        return [text]
    blocks = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ!?.])', text)
    chunks, current = [], ''
    for b in blocks:
        if len(current) + len(b) < limit:
            current += b
        else:
            if '```' in current and current.count('```') % 2 != 0:
                current += '\n```\n'
            chunks.append(current.strip())
            current = b
    if current:
        if '```' in current and current.count('```') % 2 != 0:
            current += '\n```\n'
        chunks.append(current.strip())
    return chunks

def get_runnable(student_id: str, prompt: str):
    llm = ChatGoogleGenerativeAI(
        model="models/gemini-2.0-flash",
        temperature=0.7,
        google_api_key=GOOGLE_API_KEY,
        max_output_tokens=450
    )
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", prompt),
        MessagesPlaceholder("history"),
        ("human", "{input}")
    ])
    chain = chat_prompt | llm

    def history_store(session_id):
        if session_id not in user_sessions:
            chat_history = InMemoryChatMessageHistory()
            sid = session_id.replace("student-", "")
            if sid in student_logs:
                for entry in student_logs[sid]:
                    role = entry["role"]
                    content = entry["content"]
                    if role == "student":
                        chat_history.add_user_message(content)
                    elif role == "ai":
                        chat_history.add_ai_message(content)
            user_sessions[session_id] = chat_history
        return user_sessions[session_id]

    return RunnableWithMessageHistory(
        chain,
        lambda session_id: history_store(session_id),
        input_messages_key="input",
        history_messages_key="history"
    )


@client.event
async def on_ready():
    print(f"âœ… åŠ©æ•™ä¸Šç·šå›‰ï¼Logged in as {client.user}")

last_message_time = {}

@client.event
async def on_message(message):
    if message.author == client.user:
        return

    channel_id = message.channel.id
    now = time.time()

    if channel_id in last_message_time and now - last_message_time[channel_id] < 1:
        await message.channel.send("âš ï¸ è«‹ç¨ç­‰ä¸€ä¸‹å†ç™¼é€è¨Šæ¯å–”ï¼")
        return

    last_message_time[channel_id] = now

    channel_name = message.channel.name
    parts = channel_name.split("-")

    if len(parts) != 2 or not parts[0].isdigit() or not parts[1].isdigit():
        await message.channel.send("âš ï¸ é »é“åç¨±æ‡‰ç‚ºã€å­¸è™Ÿ-ç­‰ç´šã€æ ¼å¼ï¼Œä¾‹å¦‚ `10531-01`")
        return

    student_id = parts[0]
    student_level = parts[1]
    content = message.content.strip()
    processed = preprocess_message(content)

    # æ¸¬è©¦æŒ‡ä»¤ï¼šå¼·åˆ¶æ‘˜è¦
    if content == "-summarize":
        update_summary_if_needed(student_id)
        await message.channel.send("âœ… å·²æ‰‹å‹•è§¸ç™¼æ‘˜è¦")
        return

    session_id = f"student-{student_id}"
    prompt = get_system_prompt(student_level)
    chat = get_runnable(student_id, prompt)
    log_message(student_id, "student", content)

    try:
        response = await chat.ainvoke({"input": processed}, config={"configurable": {"session_id": session_id}})
        text = response.content if hasattr(response, "content") else str(response)
        log_message(student_id, "ai", text)

        for part in semantic_split(text):
            await message.channel.send(part)

        update_summary_if_needed(student_id)

    except Exception as e:
        await message.channel.send(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise e
# ğŸ§  æ¦‚è¦ç”¢ç”Ÿ
def update_summary_if_needed(student_id: str):
    session_id = f"student-{student_id}"
    history_obj = user_sessions.get(session_id)

    if not history_obj:
        print(f"[DEBUG] âŒ æ‰¾ä¸åˆ°è¨˜æ†¶é«”ï¼š{session_id}")
        return

    history = history_obj.messages
    print(f"[DEBUG] ğŸ§  å˜—è©¦ç‚º student {student_id} ç”¢ç”Ÿæ‘˜è¦ï¼Œè¨Šæ¯æ•¸ï¼š{len(history)}")

    if len(history) > 12:
        print(f"[DEBUG] âœ… è¨Šæ¯æ•¸ç¬¦åˆæ¢ä»¶ï¼Œé–‹å§‹æ‘˜è¦å‰æ®µå°è©±")
        try:
            text_history = []
            for msg in history[:-10]:
                if isinstance(msg, HumanMessage):
                    print(f"[DEBUG] ğŸ§ Human: {msg.content[:30]}...")
                    text_history.append(f"å­¸ç”Ÿï¼š{msg.content}")
                elif isinstance(msg, AIMessage):
                    print(f"[DEBUG] ğŸ¤– AI: {msg.content[:30]}...")
                    text_history.append(f"åŠ©æ•™ï¼š{msg.content}")
                else:
                    print(f"[DEBUG] âš ï¸ æœªçŸ¥è¨Šæ¯é¡å‹ï¼š{type(msg)}")

            if not text_history:
                print("[DEBUG] âš ï¸ æ²’æœ‰å¯æ‘˜è¦çš„è¨Šæ¯ï¼Œç•¥éå„²å­˜")
                return

            combined = "\n".join(text_history)
            summary_text = f"é€™æ˜¯èˆ‡å­¸ç”Ÿ {student_id} çš„å°è©±æ‘˜è¦ï¼š\n{combined[:2000]}..."
            save_summary(student_id, summary_text)
            print(f"[LOG] âœï¸ è‡ªå‹•æ›´æ–°æ‘˜è¦ï¼šstudent {student_id}")
        except Exception as e:
            print(f"[ERROR] âŒ æ‘˜è¦æ›´æ–°å¤±æ•—ï¼š{e}")
    else:
        print(f"[DEBUG] âŒ å°šæœªé”æ‘˜è¦æ¢ä»¶ï¼ˆç›®å‰ {len(history)} ç­†ï¼‰")




# âœ… é—œæ©Ÿæ™‚æ­¸æª” + å„²å­˜æ‘˜è¦ + æ¸…é™¤å¿«å–
def graceful_exit(signum, frame):
    print("[LOG] âš ï¸ æ”¶åˆ°é—œæ©Ÿè¨Šè™Ÿï¼Œé–‹å§‹æ­¸æª”...")
    archive_now()
    for key in user_sessions:
        student_id = key.replace("student-", "")
        update_summary_if_needed(student_id)  # âœ… ä½¿ç”¨çµ±ä¸€æ‘˜è¦é‚è¼¯
    try:
        os.remove("logs/student_logs_tmp.json")
        print("[LOG] ğŸ§¹ æ¸…é™¤æš«å­˜ student_logs_tmp.json")
    except:
        pass
    print("[LOG] âœ… é—œæ©Ÿå®Œæˆ")
    exit(0)

signal.signal(signal.SIGINT, graceful_exit)
signal.signal(signal.SIGTERM, graceful_exit)

client.run(DISCORD_BOT_TOKEN)
